{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Layer, Dense, Dropout\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, GlobalAveragePooling2D\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture Notes\n",
    "- need to handle variable length inputs\n",
    "- Input spectrograms or MFCCs\n",
    "- use tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '101415-3-0-2.wav',\n",
       " 'fold': 'fold1',\n",
       " 'class': 3,\n",
       " 'spectrogram': array([[7.5957165e+00, 1.1212744e+01, 8.0402737e+00, ..., 4.4006630e+01,\n",
       "         1.2173186e+02, 6.7787331e+01],\n",
       "        [7.7117748e+00, 7.3635635e+00, 7.2426586e+00, ..., 2.2728676e+01,\n",
       "         5.1560234e+01, 1.8138807e+01],\n",
       "        [4.9771862e+00, 1.8851723e+01, 2.3887272e+01, ..., 7.8501983e+00,\n",
       "         1.3240112e+01, 1.4655676e+01],\n",
       "        ...,\n",
       "        [1.4012260e-02, 3.4747527e-03, 4.4790872e-12, ..., 3.9292393e-12,\n",
       "         2.6693215e-07, 5.3465010e-06],\n",
       "        [1.3874512e-02, 3.4418404e-03, 3.7548515e-12, ..., 4.9936058e-12,\n",
       "         1.7793683e-07, 3.6044783e-06],\n",
       "        [1.3787241e-02, 3.4209301e-03, 4.3137828e-12, ..., 1.9792165e-12,\n",
       "         1.2118500e-07, 2.4911822e-06]], dtype=float32)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\proba\\OneDrive\\Documents\\Booz Training\\generative-ai-audio-enhancement-classification\\data\\features\\fold1\\spectrograms.pickle\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = []\n",
    "labels = []\n",
    "for row in data:\n",
    "    spectrograms.append(row['spectrogram'])\n",
    "    labels.append(row['class'])\n",
    "\n",
    "target_shape = (128, 238)\n",
    "\n",
    "# Pad each numpy array in each tuple\n",
    "padded_data = []\n",
    "for item in spectrograms:\n",
    "    padded_item = tuple(\n",
    "        pad_sequences(\n",
    "            [array], maxlen=target_shape[1], dtype='float32', padding='post', truncating='post', value=0.0\n",
    "        )[0]\n",
    "        for array in item\n",
    "    )\n",
    "    padded_data.append(padded_item)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorFlow dataset\n",
    "one_hot_labels = tf.one_hot(labels, depth=10)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((padded_data, one_hot_labels.numpy()))\n",
    "\n",
    "# Optionally batch the dataset\n",
    "batch_size = 32\n",
    "dataset = dataset.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractPatches(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ExtractPatches, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        shape = tf.shape(inputs)\n",
    "        reshaped_data = tf.reshape(inputs, (-1, shape[1], shape[2], 1))\n",
    "        patches = tf.image.extract_patches(reshaped_data, sizes=[1, 16, 16, 1], strides=[1, 8, 8, 1], rates=[1,1,1,1], padding='SAME')\n",
    "        return patches\n",
    "\n",
    "def embed(data):\n",
    "   patches = ExtractPatches()(data)\n",
    "   dense = Dense(128, activation='relu')(patches)\n",
    "   return dense\n",
    "\n",
    "# Build the Transformer Block\n",
    "\n",
    "def transformer_block(x):\n",
    "    # MultiHead Attention (add only one MultiHeadAttention with 2 heads, add droput and LayerNormalization)\n",
    "    attention = MultiHeadAttention(2, key_dim = 128) (x, x)\n",
    "    attention = Dropout(.2)(attention)\n",
    "    out1 = LayerNormalization(epsilon=1e-6) (x + attention)\n",
    "\n",
    "    # Feed Forward Network (add fully connected layers)\n",
    "    ffn_output = Dense(128, activation = 'relu')(out1)\n",
    "    ffn_output = Dropout(.2)(ffn_output)\n",
    "\n",
    "    return LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "\n",
    "# Assemble full model\n",
    "\n",
    "def build_model():\n",
    "    input = Input(shape = (128,238))\n",
    "    embedding_layer = embed(input)\n",
    "\n",
    "    x = transformer_block(embedding_layer)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x =  Dropout(0.1)(x)# add droput layer\n",
    "    outputs = Dense(10, activation='sigmoid')(x)#dende layer\n",
    "\n",
    "    model = Model(input, outputs) # define inputs and outputs\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy', 'f1_score']) # define params\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "# display architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\proba\\OneDrive\\Documents\\Booz Training\\generative-ai-audio-enhancement-classification\\data\\features\")\n",
    "data_folds = []\n",
    "label_folds = []\n",
    "for root, dirs, files in os.walk(\".\"):  \n",
    "    for file in files:\n",
    "        if \"spectrograms\" in file:\n",
    "            folder = os.path.basename(root)\n",
    "            i = int(folder[-1])\n",
    "            relative_path = os.path.join(folder, file)\n",
    "            with open(relative_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "\n",
    "            specs = []\n",
    "            lbls = []\n",
    "            for row in data:\n",
    "                specs.append(row['spectrogram'])\n",
    "                lbls.append(row['class'])\n",
    "\n",
    "            padded_data = []\n",
    "            target_shape = (128, 238)\n",
    "            specs = specs[0:50]\n",
    "            lbls = lbls[0:50]\n",
    "            for item in specs:\n",
    "                padded_item = tuple(\n",
    "                    pad_sequences(\n",
    "                        [array], maxlen=target_shape[1], dtype='float32', padding='post', truncating='post', value=0.0\n",
    "                    )[0]\n",
    "                    for array in item\n",
    "                )\n",
    "                padded_data.append(padded_item)\n",
    "\n",
    "            one_hot_labels = tf.one_hot(lbls, depth=10)\n",
    "            data_folds.append(padded_data)\n",
    "            label_folds.append(one_hot_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 184ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0204\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 178ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0211\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 227ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0198\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0172\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 250ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0172\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 186ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0152\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 241ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0145\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0147\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0138\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0132\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - f1_score: 0.4000 - loss: 0.0558\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 222ms/step - accuracy: 1.0000 - f1_score: 0.8562 - loss: 0.0356\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214ms/step - accuracy: 1.0000 - f1_score: 0.8562 - loss: 0.0269\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 239ms/step - accuracy: 1.0000 - f1_score: 0.8562 - loss: 0.0241\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 249ms/step - accuracy: 1.0000 - f1_score: 0.8562 - loss: 0.0221\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 195ms/step - accuracy: 1.0000 - f1_score: 0.8562 - loss: 0.0224\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 1.0000 - f1_score: 0.8562 - loss: 0.0213\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 192ms/step - accuracy: 1.0000 - f1_score: 0.8562 - loss: 0.0179\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 1.0000 - f1_score: 0.8562 - loss: 0.0187\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 246ms/step - accuracy: 1.0000 - f1_score: 0.8562 - loss: 0.0168\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 1.0000 - f1_score: 0.8562 - loss: 0.0162\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - f1_score: 0.3000 - loss: 0.0036  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 247ms/step - accuracy: 1.0000 - f1_score: 0.8750 - loss: 0.0148\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 229ms/step - accuracy: 1.0000 - f1_score: 0.8750 - loss: 0.0153\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 1.0000 - f1_score: 0.8750 - loss: 0.0134\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - accuracy: 1.0000 - f1_score: 0.8750 - loss: 0.0135\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 221ms/step - accuracy: 1.0000 - f1_score: 0.8750 - loss: 0.0121\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 196ms/step - accuracy: 1.0000 - f1_score: 0.8750 - loss: 0.0115\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 225ms/step - accuracy: 1.0000 - f1_score: 0.8750 - loss: 0.0118\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 201ms/step - accuracy: 1.0000 - f1_score: 0.8750 - loss: 0.0110\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 1.0000 - f1_score: 0.8750 - loss: 0.0108\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 198ms/step - accuracy: 1.0000 - f1_score: 0.8750 - loss: 0.0104\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - f1_score: 0.4000 - loss: 0.0061\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 224ms/step - accuracy: 1.0000 - f1_score: 0.8875 - loss: 0.0115\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 196ms/step - accuracy: 1.0000 - f1_score: 0.8875 - loss: 0.0111\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - accuracy: 1.0000 - f1_score: 0.8875 - loss: 0.0115\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 200ms/step - accuracy: 1.0000 - f1_score: 0.8875 - loss: 0.0106\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 217ms/step - accuracy: 1.0000 - f1_score: 0.8875 - loss: 0.0098\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 201ms/step - accuracy: 1.0000 - f1_score: 0.8875 - loss: 0.0098\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214ms/step - accuracy: 1.0000 - f1_score: 0.8875 - loss: 0.0100\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 211ms/step - accuracy: 1.0000 - f1_score: 0.8875 - loss: 0.0095\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - accuracy: 1.0000 - f1_score: 0.8875 - loss: 0.0086\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 1.0000 - f1_score: 0.8875 - loss: 0.0080\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - f1_score: 0.4333 - loss: 0.0026\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 211ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0077\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 202ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0077\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 230ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0069\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 200ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0071\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 245ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0073\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 232ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0067\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 253ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0066\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 224ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0064\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 233ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0063\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 192ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0061\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - f1_score: 0.6667 - loss: 0.0064\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 211ms/step - accuracy: 1.0000 - f1_score: 0.8375 - loss: 0.0064\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 216ms/step - accuracy: 1.0000 - f1_score: 0.8375 - loss: 0.0058\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 243ms/step - accuracy: 1.0000 - f1_score: 0.8375 - loss: 0.0056\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 175ms/step - accuracy: 1.0000 - f1_score: 0.8375 - loss: 0.0057\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 244ms/step - accuracy: 1.0000 - f1_score: 0.8375 - loss: 0.0053\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 200ms/step - accuracy: 1.0000 - f1_score: 0.8375 - loss: 0.0053\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 259ms/step - accuracy: 1.0000 - f1_score: 0.8375 - loss: 0.0051\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 198ms/step - accuracy: 1.0000 - f1_score: 0.8375 - loss: 0.0045\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 234ms/step - accuracy: 1.0000 - f1_score: 0.8375 - loss: 0.0045\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - accuracy: 1.0000 - f1_score: 0.8375 - loss: 0.0043\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - f1_score: 0.3000 - loss: 0.0068\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0049\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 197ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0052\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 228ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0050\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 202ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0047\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0047\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0043\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 234ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0045\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 245ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0044\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0040\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 262ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0040\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - f1_score: 0.5667 - loss: 0.0026\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 226ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0038\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 243ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0038\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 213ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0040\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 250ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0038\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 229ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0038\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 230ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0035\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 243ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0036\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0036\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 244ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0032\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 222ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - f1_score: 0.2333 - loss: 0.0027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 226ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0034\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 243ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0033\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0034\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 249ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0036\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 215ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0032\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 244ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0033\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 246ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0035\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 215ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0030\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0031\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - f1_score: 0.3000 - loss: 6.8196e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 248ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0029\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 245ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0031\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0033\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 247ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0029\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 199ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0029\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 244ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0027\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 237ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0027\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0027\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 187ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0029\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 190ms/step - accuracy: 1.0000 - f1_score: 0.8625 - loss: 0.0028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - f1_score: 0.2667 - loss: 6.0359e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Average Loss: 0.008619855722645297\n",
      "Average Accuracy: 1.0\n",
      "Average F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "\n",
    "fold_losses = []\n",
    "fold_accuracies = []\n",
    "fold_f1_scores = []\n",
    "for fold in range(num_folds):\n",
    "    train_data, val_data = [], []\n",
    "    train_labels, val_labels = [], []\n",
    "    for i, (data_fold, label_fold) in enumerate(zip(data_folds, label_folds)):\n",
    "        if i == fold:\n",
    "            val_data.extend(data_fold)\n",
    "            val_labels.extend(label_fold)\n",
    "        else:\n",
    "            train_data.extend(data_fold)\n",
    "            train_labels.extend(label_fold)\n",
    "\n",
    "    # Convert lists to numpy arrays if needed\n",
    "    train_data = np.array(train_data)\n",
    "    val_data = np.array(val_data)\n",
    "    train_labels = np.array(train_labels)\n",
    "    val_labels = np.array(val_labels)\n",
    "\n",
    "    \n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "    # Optionally batch the dataset\n",
    "    batch_size = 32\n",
    "    train_dataset = train_dataset.batch(batch_size=batch_size)\n",
    "\n",
    "    validation_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels)).batch(batch_size=batch_size).shuffle(buffer_size=100)\n",
    "\n",
    "\n",
    "    # Train your model on train_data and train_labels\n",
    "    model.fit(train_dataset, epochs=10) #define params\n",
    "    # Evaluate your model on val_data and val_labels\n",
    "    results = model.evaluate(validation_dataset)\n",
    "    fold_loss = results[0]\n",
    "    fold_accuracy = results[1]\n",
    "\n",
    "    fold_losses.append(fold_loss)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    fold_predictions = model.predict(val_data)\n",
    "    val_labels_indices = np.argmax(val_labels, axis=1)\n",
    "    fold_f1 = f1_score(val_labels_indices, fold_predictions.argmax(axis=1), average='macro')\n",
    "    fold_f1_scores.append(fold_f1)\n",
    "    # Calculate performance metric (e.g., accuracy) for this fold\n",
    "\n",
    "# Calculate average performance metric across all folds\n",
    "#average_accuracy = ...\n",
    "avg_loss = sum(fold_losses) / len(fold_losses)\n",
    "avg_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "avg_f1_score = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(\"Average Loss:\", avg_loss)\n",
    "print(\"Average Accuracy:\", avg_accuracy)\n",
    "print(\"Average F1 Score:\", avg_f1_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai-audio-enhance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
